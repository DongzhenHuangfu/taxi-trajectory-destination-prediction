{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import the labrary and define the function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import csv\n",
    "import pickle\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## define a function to translate the string data into a float list\n",
    "\n",
    "def str2array(string):    \n",
    "    together = ''\n",
    "    for i in string:\n",
    "        if(i != '['):\n",
    "            together += i\n",
    "    \n",
    "    first = together.split(\"],\")\n",
    "    ret = []\n",
    "    \n",
    "    for i in range(len(first)):\n",
    "        if(i==len(first)-1):\n",
    "            second = ''\n",
    "            for j in first[i]:\n",
    "                if(j!=']'):\n",
    "                    second += j\n",
    "            second = second.split(\",\")\n",
    "        else:\n",
    "            second = first[i].split(\",\")\n",
    "        ret.append([float(second[0]), float(second[1])])\n",
    "    return ret\n",
    "\n",
    "## define a function for exploring the maximum and minimum length of the track data\n",
    "\n",
    "def find_maxmin(data):\n",
    "    maximum = 0\n",
    "    minimum = 99999\n",
    "    for track in data:\n",
    "        if(len(track) > maximum):\n",
    "            maximum = len(track)\n",
    "        if(len(track) < minimum):\n",
    "            minimum = len(track)\n",
    "    return maximum, minimum\n",
    "\n",
    "## def a functino for exploring the distribution of the track length\n",
    "\n",
    "def count(data, number = 10, maximum = 4000):\n",
    "    count_num = []\n",
    "    part = maximum//number\n",
    "    level = part*np.array(range(1+number))\n",
    "    print(\"level is:\", level)\n",
    "    \n",
    "    for i in range(number):\n",
    "        count_num.append(0)\n",
    "    \n",
    "    for line in data:\n",
    "        for i in range(len(level)-1):\n",
    "            if((len(line) < level[i+1]) & (len(line) >= level[i])):\n",
    "                count_num[i] += 1\n",
    "                continue\n",
    "    return count_num\n",
    "\n",
    "## define a function for exploring the number of the track which is above a value\n",
    "\n",
    "def above(data, level):\n",
    "    count = 0\n",
    "    for line in data:\n",
    "        if(len(line)>=level):\n",
    "            count += 1            \n",
    "    return count\n",
    "\n",
    "## define a function for selecting track data\n",
    "\n",
    "def select_data(track, place):\n",
    "    ret = []\n",
    "    for i in place:\n",
    "        ret.append(track[i])\n",
    "    return ret\n",
    "\n",
    "def pick_data(data, data_length):\n",
    "    ret_train = []\n",
    "    ret_label = []\n",
    "    n = 0\n",
    "    for i in range(len(data)):\n",
    "        if(len(data[i]) > data_length):\n",
    "            split = len(data[i])//data_length\n",
    "            ret_train.append([])\n",
    "            for j in range(data_length):\n",
    "                ret_train[n].append(data[i][split*j][0])\n",
    "                ret_train[n].append(data[i][split*j][1])\n",
    "            ret_label.append(data[i][len(data[i])-1])\n",
    "            n += 1\n",
    "    return ret_train, ret_label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import, process and save the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "## read in the data and seperate it into two parts\n",
    "## (one set is the fully recorded data, the other one is the set of not complete data)\n",
    "files = glob.glob(\"./split_data/part*.csv\")\n",
    "data_false = []\n",
    "data_true = []\n",
    "for table in files:\n",
    "    with open(table,'r') as file:\n",
    "        lines = list(csv.reader(file))\n",
    "        for i in range(1, len(lines)):\n",
    "            if(len(lines[i])==0):\n",
    "                continue\n",
    "            if(lines[i][7]==\"False\"):\n",
    "                if(len(lines[i][8])==2):\n",
    "                    data_false.append([])\n",
    "                else:\n",
    "                    track = str2array(lines[i][8])\n",
    "                    data_false.append(track)\n",
    "            elif(lines[i][7]==\"True\"):\n",
    "                if(len(lines[i][8])==2):\n",
    "                    data_true.append([])\n",
    "                else:\n",
    "                    track = str2array(lines[i][8])\n",
    "                    data_true.append(track)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "## save the data into a pickle file\n",
    "data_dict = {'data_true': data_true, 'data_false': data_false}\n",
    "with open('./trackdata.pickle','wb') as file:\n",
    "    pickle.dump(data_dict, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./trackdata.pickle', 'rb') as file:\n",
    "    data_dict = pickle.load(file)\n",
    "    data_true = data_dict['data_true']\n",
    "    data_false = data_dict['data_false']    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explore the maximum and minimum length of the track data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Track in data_false:\n",
      "Maximum: 3881, minimum: 0\n",
      "Track in data_true:\n",
      "Maximum: 483, minimum: 1\n"
     ]
    }
   ],
   "source": [
    "max_false, min_false = find_maxmin(data_false)\n",
    "max_true, min_true = find_maxmin(data_true)\n",
    "\n",
    "print(\"Track in data_false:\")\n",
    "print(\"Maximum: %d, minimum: %d\" % (max_false, min_false))\n",
    "\n",
    "print(\"Track in data_true:\")\n",
    "print(\"Maximum: %d, minimum: %d\" % (max_true, min_true))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explore the distribution of the track length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "level is: [   0  400  800 1200 1600 2000 2400 2800 3200 3600 4000]\n",
      "[1707207, 2808, 437, 105, 58, 26, 12, 2, 2, 3]\n"
     ]
    }
   ],
   "source": [
    "num_false = count(data_false)\n",
    "print(num_false)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The amount of the data_false is: 1710660\n"
     ]
    }
   ],
   "source": [
    "print(\"The amount of the data_false is:\", len(data_false))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "level is: [  0  50 100 150 200 250 300 350 400 450 500]\n",
      "[6, 2, 0, 0, 0, 1, 0, 0, 0, 1]\n",
      "The amount of the data_true is: 10\n"
     ]
    }
   ],
   "source": [
    "num_true = count(data_true, maximum = 500)\n",
    "print(num_true)\n",
    "print(\"The amount of the data_true is:\", len(data_true))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FInd out how many tracks are about a value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyse the track data without missing points......\n",
      "The number of the track data without missing points is: 1710660\n",
      "\n",
      "The number of track with the length above 10 in data_true is: 1641024, 95.93%\n",
      "The number of track with the length above 15 in data_true is: 1600460, 93.56%\n",
      "The number of track with the length above 20 in data_true is: 1514478, 88.53%\n",
      "The number of track with the length above 30 in data_true is: 1233766, 72.12%\n",
      "The number of track with the length above 50 in data_true is: 628873, 36.76%\n",
      "The number of track with the length above 60 in data_true is: 416203, 24.33%\n",
      "The number of track with the length above 70 in data_true is: 273018, 15.96%\n",
      "The number of track with the length above 80 in data_true is: 183744, 10.74%\n",
      "The number of track with the length above 90 in data_true is: 128391, 7.51%\n",
      "The number of track with the length above 100 in data_true is: 93798, 5.48%\n",
      "The number of track with the length above 150 in data_true is: 30296, 1.77%\n",
      "The number of track with the length above 200 in data_true is: 15145, 0.89%\n",
      "The number of track with the length above 300 in data_true is: 6349, 0.37%\n"
     ]
    }
   ],
   "source": [
    "print(\"Analyse the track data without missing points......\")\n",
    "print(\"The number of the track data without missing points is:\", len(data_false))\n",
    "print()\n",
    "level_false = [10, 15, 20, 30, 50, 60, 70, 80, 90, 100, 150, 200, 300]\n",
    "for a in level_false:\n",
    "    number = above(data_false, a)\n",
    "    percent = number / len(data_false)\n",
    "    print(\"The number of track with the length above %d in data_true is: %d, %.2f%%\" % \n",
    "          ( a, number, percent*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyse the track data with missing points......\n",
      "The number of the track data with missing points is: 10\n",
      "\n",
      "The number of track with the length above 10 in data_true is: 8, 80.00%\n",
      "The number of track with the length above 20 in data_true is: 6, 60.00%\n",
      "The number of track with the length above 30 in data_true is: 5, 50.00%\n",
      "The number of track with the length above 50 in data_true is: 4, 40.00%\n",
      "The number of track with the length above 60 in data_true is: 2, 20.00%\n",
      "The number of track with the length above 300 in data_true is: 1, 10.00%\n"
     ]
    }
   ],
   "source": [
    "print(\"Analyse the track data with missing points......\")\n",
    "print(\"The number of the track data with missing points is:\", len(data_true))\n",
    "print()\n",
    "\n",
    "level_true = [10, 20, 30, 50, 60, 300]\n",
    "for a in level_true:\n",
    "    number = above(data_true, a)\n",
    "    percent = number / len(data_true)\n",
    "    print(\"The number of track with the length above %d in data_true is: %d, %.2f%%\" % \n",
    "          ( a, number, percent*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Selecte the data from the track"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of useful data is: 1635931\n"
     ]
    }
   ],
   "source": [
    "## define the index array for selecting\n",
    "data_length = 10\n",
    "\n",
    "train_data, train_label = pick_data(data_false, data_length)\n",
    "print(\"The number of useful data is:\", len(train_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1635931 1635931\n"
     ]
    }
   ],
   "source": [
    "print(len(train_data), len(train_label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "## save the data into a pickle file\n",
    "data_dict = {'train_data10': train_data, 'train_label10': train_label}\n",
    "with open('./train_data.pickle','wb') as file:\n",
    "    pickle.dump(data_dict, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./train_data.pickle', 'rb') as file:\n",
    "    data_dict = pickle.load(file)\n",
    "    train_data = data_dict['train_data10']\n",
    "    train_label = data_dict['train_label10']    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-8.618643, 41.141412], [-8.620326, 41.14251], [-8.623953, 41.144373], [-8.627373, 41.144697], [-8.632746, 41.14692], [-8.629938, 41.150385], [-8.629128, 41.15124], [-8.628687, 41.152374], [-8.630838, 41.15268], [-8.631144, 41.154489]]\n"
     ]
    }
   ],
   "source": [
    "print(train_data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "## divide the area into n parts, only predict the area for the destination\n",
    "max_x = -99999.;\n",
    "max_y = -99999.;\n",
    "min_x = 99999.;\n",
    "min_y = 99999.;\n",
    "\n",
    "for point in train_label:\n",
    "    if max_x < point[0]: max_x = point[0]\n",
    "    if max_y < point[1]: max_y = point[1]\n",
    "    if min_x > point[0]: min_x = point[0]\n",
    "    if min_y > point[1]: min_y = point[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-13.476465 38.53413 -5.793111 44.119224\n"
     ]
    }
   ],
   "source": [
    "print(min_x, min_y, max_x, max_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "div_len = 0.15\n",
    "area = []\n",
    "labels = []\n",
    "x = min_x\n",
    "y = min_y\n",
    "i = 0\n",
    "while(x < max_x + div_len):\n",
    "    area.append([])\n",
    "    y = min_y\n",
    "    while(y < max_y + div_len):\n",
    "        area[i].append([x, y])\n",
    "        y += div_len\n",
    "    i += 1\n",
    "    x += div_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53 rows, 39 columns\n",
      "Together 2067 areas\n"
     ]
    }
   ],
   "source": [
    "print(\"%d rows, %d columns\" % (len(area),len(area[0])))\n",
    "print(\"Together %d areas\" % (len(area) * len(area[0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-13.476465, 38.53413], [-13.476465, 38.684129999999996], [-13.476465, 38.834129999999995], [-13.476465, 38.98412999999999], [-13.476465, 39.13412999999999], [-13.476465, 39.28412999999999], [-13.476465, 39.43412999999999], [-13.476465, 39.58412999999999], [-13.476465, 39.734129999999986], [-13.476465, 39.884129999999985], [-13.476465, 40.03412999999998], [-13.476465, 40.18412999999998], [-13.476465, 40.33412999999998], [-13.476465, 40.48412999999998], [-13.476465, 40.63412999999998], [-13.476465, 40.784129999999976], [-13.476465, 40.934129999999975], [-13.476465, 41.08412999999997], [-13.476465, 41.23412999999997], [-13.476465, 41.38412999999997], [-13.476465, 41.53412999999997], [-13.476465, 41.68412999999997], [-13.476465, 41.834129999999966], [-13.476465, 41.984129999999965], [-13.476465, 42.13412999999996], [-13.476465, 42.28412999999996], [-13.476465, 42.43412999999996], [-13.476465, 42.58412999999996], [-13.476465, 42.73412999999996], [-13.476465, 42.884129999999956], [-13.476465, 43.034129999999955], [-13.476465, 43.18412999999995], [-13.476465, 43.33412999999995], [-13.476465, 43.48412999999995], [-13.476465, 43.63412999999995], [-13.476465, 43.78412999999995], [-13.476465, 43.934129999999946], [-13.476465, 44.084129999999945], [-13.476465, 44.23412999999994]]\n",
      "\n",
      "[[-7.626464999999985, 38.53413], [-7.626464999999985, 38.684129999999996], [-7.626464999999985, 38.834129999999995], [-7.626464999999985, 38.98412999999999], [-7.626464999999985, 39.13412999999999], [-7.626464999999985, 39.28412999999999], [-7.626464999999985, 39.43412999999999], [-7.626464999999985, 39.58412999999999], [-7.626464999999985, 39.734129999999986], [-7.626464999999985, 39.884129999999985], [-7.626464999999985, 40.03412999999998], [-7.626464999999985, 40.18412999999998], [-7.626464999999985, 40.33412999999998], [-7.626464999999985, 40.48412999999998], [-7.626464999999985, 40.63412999999998], [-7.626464999999985, 40.784129999999976], [-7.626464999999985, 40.934129999999975], [-7.626464999999985, 41.08412999999997], [-7.626464999999985, 41.23412999999997], [-7.626464999999985, 41.38412999999997], [-7.626464999999985, 41.53412999999997], [-7.626464999999985, 41.68412999999997], [-7.626464999999985, 41.834129999999966], [-7.626464999999985, 41.984129999999965], [-7.626464999999985, 42.13412999999996], [-7.626464999999985, 42.28412999999996], [-7.626464999999985, 42.43412999999996], [-7.626464999999985, 42.58412999999996], [-7.626464999999985, 42.73412999999996], [-7.626464999999985, 42.884129999999956], [-7.626464999999985, 43.034129999999955], [-7.626464999999985, 43.18412999999995], [-7.626464999999985, 43.33412999999995], [-7.626464999999985, 43.48412999999995], [-7.626464999999985, 43.63412999999995], [-7.626464999999985, 43.78412999999995], [-7.626464999999985, 43.934129999999946], [-7.626464999999985, 44.084129999999945], [-7.626464999999985, 44.23412999999994]]\n"
     ]
    }
   ],
   "source": [
    "print(area[0])\n",
    "print()\n",
    "print(area[39])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "for point in train_label:\n",
    "    find = False    \n",
    "    for i in range(len(area) - 1):\n",
    "        if((point[0] >= area[i][0][0]) & (point[0] < area[i+1][0][0])):\n",
    "            for j in range(len(area[i]) - 1):\n",
    "                if((point[1] >= area[i][j][1]) & (point[1] < area[i][j+1][1])):\n",
    "                    find = True \n",
    "                    labels.append((i,j))\n",
    "                    break\n",
    "            if find: break\n",
    "    if not find:\n",
    "        print(\"Error at i = %d, j = %d\" % (i, j))\n",
    "        print(\"Point:\", point)\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1635931 1635931 1635931\n"
     ]
    }
   ],
   "source": [
    "print(len(labels), len(train_data), len(train_label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-8.630838, 41.154489]\n",
      "[-8.618643, 41.141412, -8.620326, 41.14251, -8.623953, 41.144373, -8.627373, 41.144697, -8.632746, 41.14692, -8.629938, 41.150385, -8.629128, 41.15124, -8.628687, 41.152374, -8.630838, 41.15268, -8.631144, 41.154489]\n",
      "\n",
      "[-8.66574, 41.170671]\n",
      "[-8.639847, 41.159826, -8.640351, 41.159871, -8.642196, 41.160114, -8.644455, 41.160492, -8.646921, 41.160951, -8.649999, 41.161491, -8.653167, 41.162031, -8.656434, 41.16258, -8.660178, 41.163192, -8.663112, 41.163687]\n",
      "\n",
      "[-8.61597, 41.14053]\n",
      "[-8.612964, 41.140359, -8.618472, 41.141412, -8.6319, 41.146461, -8.62875, 41.152662, -8.642205, 41.154021, -8.649837, 41.1543, -8.65008, 41.154291, -8.649198, 41.152374, -8.647587, 41.148405, -8.635338, 41.147964]\n",
      "\n",
      "[-8.607996, 41.142915]\n",
      "[-8.574678, 41.151951, -8.574723, 41.151933, -8.577135, 41.150232, -8.580744, 41.14503, -8.610012, 41.146479, -8.587197, 41.149224, -8.592543, 41.146614, -8.598816, 41.146101, -8.602785, 41.145705, -8.605854, 41.142555]\n",
      "\n",
      "[-8.687268, 41.178087]\n",
      "[-8.645994, 41.18049, -8.646048, 41.180049, -8.649495, 41.178465, -8.654049, 41.177196, -8.656353, 41.177853, -8.662518, 41.177619, -8.667432, 41.178537, -8.671374, 41.17518, -8.676918, 41.171841, -8.682615, 41.173191]\n",
      "\n",
      "[-8.578224, 41.160717]\n",
      "[-8.615502, 41.140674, -8.613351, 41.14152, -8.607537, 41.141295, -8.599833, 41.141916, -8.592993, 41.140008, -8.587026, 41.142753, -8.581086, 41.143698, -8.577594, 41.144688, -8.580168, 41.147136, -8.579808, 41.151879]\n",
      "\n",
      "[-8.603973, 41.142816]\n",
      "[-8.57952, 41.145948, -8.584092, 41.146164, -8.586171, 41.148018, -8.590401, 41.150016, -8.593668, 41.15097, -8.597466, 41.148909, -8.600688, 41.148585, -8.601768, 41.147289, -8.603739, 41.146578, -8.604477, 41.145327]\n",
      "\n",
      "[-8.6247, 41.161554]\n",
      "[-8.617563, 41.146182, -8.615754, 41.145426, -8.615142, 41.147046, -8.617455, 41.147235, -8.618796, 41.148603, -8.621055, 41.150565, -8.620821, 41.15547, -8.62092, 41.157225, -8.624664, 41.159718, -8.624718, 41.161563]\n",
      "\n",
      "[-8.589402, 41.163309]\n",
      "[-8.611794, 41.140557, -8.612622, 41.140503, -8.615844, 41.140485, -8.614395, 41.141979, -8.611488, 41.144787, -8.610255, 41.143401, -8.606565, 41.142348, -8.604297, 41.1453, -8.601039, 41.145759, -8.598681, 41.14827]\n",
      "\n",
      "[-8.604594, 41.134158]\n",
      "[-8.615907, 41.140557, -8.614449, 41.141088, -8.613522, 41.14143, -8.609904, 41.140827, -8.609301, 41.139522, -8.609544, 41.138865, -8.610777, 41.137551, -8.611452, 41.136012, -8.610624, 41.134563, -8.609319, 41.134446]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    print(train_label[i])\n",
    "    print(train_data[i])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(32, 17), (32, 17), (32, 17), (32, 17), (32, 18), (32, 17), (32, 17), (32, 17), (32, 17), (32, 17), (32, 18), (32, 17), (32, 17), (32, 17), (32, 17), (32, 17), (32, 17), (32, 17), (32, 17), (31, 17), (37, 13), (32, 17), (32, 17), (32, 17), (32, 17), (32, 17), (32, 17), (32, 17), (32, 17), (32, 17), (32, 17), (32, 17), (32, 17), (32, 17), (32, 17), (32, 17), (32, 16), (32, 17), (32, 17), (32, 17), (32, 17), (32, 17), (32, 17), (32, 17), (32, 17), (32, 17), (32, 17), (32, 17), (32, 16), (32, 17), (32, 17), (32, 17), (32, 17), (32, 17), (32, 17), (32, 17), (32, 17), (32, 17), (32, 17), (32, 17), (32, 17), (32, 17), (32, 17), (32, 17), (32, 17), (32, 17), (32, 17), (32, 17), (32, 17), (32, 17), (32, 17), (32, 17), (32, 18), (32, 17), (32, 17), (32, 17), (31, 17), (32, 17), (32, 17), (32, 17), (32, 17), (32, 17), (32, 17), (32, 17), (32, 17), (32, 17), (32, 17), (32, 17), (32, 17), (32, 17), (32, 17), (32, 15), (32, 17), (32, 17), (32, 17), (32, 17), (32, 16), (32, 17), (32, 18), (32, 17), (32, 17), (31, 17), (32, 17), (32, 17), (32, 17), (32, 17), (32, 17), (32, 17), (32, 17), (32, 17), (31, 17), (32, 17), (32, 17), (32, 17), (32, 18), (32, 17), (32, 17), (32, 17), (32, 17), (32, 17), (32, 17), (32, 17), (32, 17), (32, 17), (32, 17), (32, 17), (32, 17), (32, 17), (32, 17), (32, 17), (31, 17), (32, 17), (31, 17), (32, 17), (32, 17), (32, 17), (32, 18), (32, 17), (32, 17), (32, 17), (32, 17), (32, 17), (32, 17), (32, 17), (32, 17), (32, 17), (32, 17), (32, 17), (32, 17), (32, 17), (31, 17), (32, 17), (32, 17), (32, 17), (32, 17), (32, 17), (31, 17), (32, 17), (32, 17), (32, 17), (32, 17), (32, 17), (32, 17), (32, 17), (32, 17), (32, 17), (32, 17), (32, 17), (32, 17), (32, 17), (32, 17), (32, 17), (32, 17), (32, 17), (32, 17), (32, 17), (32, 17), (32, 17), (31, 17), (32, 17), (32, 17), (32, 17), (32, 17), (32, 17), (32, 17), (32, 17), (32, 17), (32, 17), (32, 17), (32, 17), (32, 17), (32, 17), (32, 17), (32, 17), (32, 17), (32, 17), (32, 17), (32, 17), (32, 17), (32, 17)]\n",
      "[-8.627562, 41.152374]\n"
     ]
    }
   ],
   "source": [
    "print(labels[2000:2200])\n",
    "print(point)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "## cause I find the area (32,17) is very commen, I need to analyse the reapeat area and the count number of them.\n",
    "count = []\n",
    "index_set = []\n",
    "for index in range(len(labels)):\n",
    "    add = True\n",
    "    for i in range(len(index_set)):\n",
    "        if((index_set[i][0] == labels[index][0]) & (index_set[i][1] == labels[index][1])):\n",
    "            add = False\n",
    "            count[i] += 1\n",
    "            break\n",
    "    if add:\n",
    "        index_set.append(labels[index])\n",
    "        count.append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of the area: 176\n",
      "\n",
      "[(32, 17), (31, 17), (33, 17), (32, 18), (32, 16), (31, 18), (33, 18), (32, 19), (37, 13), (32, 15), (33, 16), (35, 17), (34, 17), (38, 18), (28, 1), (35, 18), (34, 19), (33, 19), (32, 14), (31, 19), (30, 10), (30, 3), (34, 18), (33, 21), (33, 15), (33, 13), (33, 11), (31, 21), (43, 20), (43, 19), (35, 19), (33, 20), (32, 21), (39, 20), (30, 8), (38, 19), (31, 20), (33, 12), (41, 15), (36, 18), (32, 22), (30, 21), (31, 14), (34, 20), (32, 12), (37, 21), (32, 13), (31, 22), (32, 20), (36, 15), (34, 16), (36, 14), (36, 19), (29, 1), (32, 23), (38, 17), (33, 22), (38, 13), (37, 17), (32, 11), (33, 23), (33, 14), (32, 7), (39, 8), (42, 18), (31, 13), (35, 21), (27, 1), (39, 18), (36, 17), (34, 12), (35, 16), (44, 13), (35, 14), (35, 20), (32, 24), (40, 21), (31, 7), (37, 0), (32, 9), (41, 21), (31, 12), (36, 20), (41, 19), (41, 13), (32, 10), (37, 14), (36, 13), (34, 13), (34, 21), (31, 11), (40, 19), (31, 8), (32, 8), (48, 20), (47, 20), (32, 5), (35, 12), (31, 9), (40, 14), (44, 20), (38, 21), (42, 20), (34, 5), (40, 17), (34, 8), (27, 2), (33, 10), (40, 12), (37, 19), (34, 15), (38, 12), (37, 15), (37, 16), (43, 22), (39, 17), (44, 21), (34, 14), (39, 21), (42, 19), (29, 2), (28, 5), (37, 18), (41, 20), (29, 5), (33, 6), (41, 12), (30, 22), (38, 16), (30, 0), (31, 4), (26, 1), (29, 7), (35, 6), (42, 21), (34, 10), (0, 2), (35, 11), (35, 13), (45, 21), (36, 12), (34, 23), (26, 0), (38, 15), (37, 12), (40, 13), (28, 4), (48, 19), (34, 11), (29, 6), (30, 4), (39, 13), (28, 2), (30, 11), (27, 5), (36, 16), (51, 37), (39, 11), (39, 19), (39, 14), (41, 18), (39, 22), (39, 12), (31, 6), (32, 6), (42, 16), (41, 16), (38, 14), (42, 17), (39, 10), (29, 0), (40, 22), (40, 18), (31, 15), (37, 20), (31, 5)]\n",
      "[1476034, 69706, 7351, 69788, 5570, 2049, 745, 124, 5, 299, 569, 82, 523, 41, 31, 107, 197, 254, 103, 372, 5, 1, 204, 11, 182, 10, 76, 27, 4, 1, 28, 314, 19, 6, 4, 5, 61, 35, 0, 42, 7, 37, 10, 34, 9, 2, 40, 4, 39, 0, 59, 5, 24, 9, 61, 8, 8, 5, 48, 2, 12, 28, 11, 2, 1, 14, 4, 1, 20, 28, 4, 14, 1, 7, 5, 0, 12, 9, 1, 3, 0, 9, 2, 4, 6, 2, 29, 4, 1, 2, 3, 8, 6, 0, 0, 0, 1, 3, 4, 2, 0, 2, 0, 0, 0, 0, 2, 0, 6, 6, 8, 3, 1, 3, 1, 6, 7, 7, 5, 1, 2, 0, 3, 2, 0, 0, 0, 4, 1, 1, 1, 0, 7, 0, 0, 2, 0, 0, 2, 0, 1, 0, 0, 3, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 2, 0, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "print(\"number of the area:\", len(index_set))\n",
    "print()\n",
    "print(index_set)\n",
    "print(count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split data into train, validation and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_for_train = []\n",
    "for i in range(53):\n",
    "    for j in range(39):\n",
    "        labels_for_train.append((i, j))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 0), (0, 1), (0, 2), (0, 3), (0, 4), (0, 5), (0, 6), (0, 7), (0, 8), (0, 9), (0, 10), (0, 11), (0, 12), (0, 13), (0, 14), (0, 15), (0, 16), (0, 17), (0, 18), (0, 19), (0, 20), (0, 21), (0, 22), (0, 23), (0, 24), (0, 25), (0, 26), (0, 27), (0, 28), (0, 29), (0, 30), (0, 31), (0, 32), (0, 33), (0, 34), (0, 35), (0, 36), (0, 37), (0, 38), (1, 0), (1, 1), (1, 2), (1, 3), (1, 4), (1, 5), (1, 6), (1, 7), (1, 8), (1, 9), (1, 10), (1, 11), (1, 12), (1, 13), (1, 14), (1, 15), (1, 16), (1, 17), (1, 18), (1, 19), (1, 20), (1, 21), (1, 22), (1, 23), (1, 24), (1, 25), (1, 26), (1, 27), (1, 28), (1, 29), (1, 30), (1, 31), (1, 32), (1, 33), (1, 34), (1, 35), (1, 36), (1, 37), (1, 38), (2, 0), (2, 1), (2, 2), (2, 3), (2, 4), (2, 5), (2, 6), (2, 7), (2, 8), (2, 9), (2, 10), (2, 11), (2, 12), (2, 13), (2, 14), (2, 15), (2, 16), (2, 17), (2, 18), (2, 19), (2, 20), (2, 21)]\n"
     ]
    }
   ],
   "source": [
    "print(labels_for_train[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = []\n",
    "\n",
    "for point in labels:\n",
    "    find = False\n",
    "    for i in range(len(labels_for_train)):\n",
    "        if((point[0] == labels_for_train[i][0]) & (point[1] == labels_for_train[i][1])):\n",
    "            Y.append(i)\n",
    "            find = True\n",
    "            break\n",
    "    if not find:\n",
    "        print(\"error\")\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1265, 1265, 1265, 1265, 1226, 1265, 1265, 1265, 1265, 1265]\n"
     ]
    }
   ],
   "source": [
    "print(Y[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(train_data, Y, test_size = 0.3, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "## save the data into a pickle file\n",
    "# need to save: data, area, labels_for_train\n",
    "data_dict = {'x_train': x_train, 'x_test': x_test, 'y_train': y_train, 'y_test': y_test, \"area\": area,\n",
    "            \"labels_for_train\": labels_for_train}\n",
    "with open('./train_data/train_for_classifier_uniform_area.pickle','wb') as file:\n",
    "    pickle.dump(data_dict, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('././train_data/train_for_classifier_uniform_area.pickle', 'rb') as file:\n",
    "    data_dict = pickle.load(file)\n",
    "    x_train = data_dict['x_train']\n",
    "    x_test = data_dict['x_test']    \n",
    "    y_train = data_dict['y_train']\n",
    "    y_test = data_dict['y_test']\n",
    "    area = data_dict['area']\n",
    "    labels_for_train = data_dict['labels_for_train']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
