{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sb\n",
    "import numpy as np\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import svm\n",
    "from sklearn.externals import joblib \n",
    "import csv\n",
    "import tensorflow as tf\n",
    "from  sklearn.utils import shuffle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get the labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "city_area = pd.read_table('endpoints.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### translate the labels into numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_index = ['[]']\n",
    "labels = []\n",
    "for i in city_area[\"name\"]:\n",
    "    if i not in labels_index:\n",
    "        labels_index.append(i)\n",
    "    index = labels_index.index(i)\n",
    "    labels.append(index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count        1704769\n",
       "unique            71\n",
       "top       Massarelos\n",
       "freq          736185\n",
       "Name: name, dtype: object"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "city_area[\"name\"].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['[]',\n",
       " 'Massarelos',\n",
       " 'Cedofeita',\n",
       " 'Lordelo do Ouro',\n",
       " 'Aldoar',\n",
       " 'Senhora da Hora',\n",
       " 'Matosinhos',\n",
       " 'Nevogilde',\n",
       " 'Le?a da Palmeira',\n",
       " 'Le?a do Balio',\n",
       " 'Mafamude',\n",
       " 'Póvoa de Varzim',\n",
       " 'Perafita',\n",
       " 'Santa Marinha',\n",
       " 'Avioso (Santa Maria)',\n",
       " 'Avioso (S?o Pedro)',\n",
       " 'Maia',\n",
       " 'Santiago',\n",
       " 'S?o Cosme',\n",
       " 'Vilar do Paraíso',\n",
       " 'Gueif?es',\n",
       " 'S?o Mamede de Infesta',\n",
       " 'Gulpilhares',\n",
       " 'Valbom',\n",
       " 'Valadares',\n",
       " 'Custóias',\n",
       " 'Bagunte',\n",
       " 'Melres',\n",
       " 'F?nzeres',\n",
       " 'Campo',\n",
       " 'Carva',\n",
       " 'S?o Pedro da Cova',\n",
       " 'Ilha',\n",
       " 'Barosa',\n",
       " 'Fornos',\n",
       " 'Guif?es',\n",
       " 'Condeixa-a-Velha',\n",
       " 'Vilar',\n",
       " 'Foz do Sousa',\n",
       " 'Vair?o',\n",
       " 'Grijó',\n",
       " 'Feira',\n",
       " 'Anta',\n",
       " 'Silva Escura',\n",
       " 'Santa Cruz do Bispo',\n",
       " 'Sandim',\n",
       " 'Mezio',\n",
       " 'Bigorne',\n",
       " 'Cep?es',\n",
       " 'Sé',\n",
       " 'Almacave',\n",
       " 'Peso da Régua',\n",
       " 'Godim',\n",
       " 'Santa Cristina',\n",
       " 'Vila Jus?',\n",
       " 'Medas',\n",
       " 'S?o Martinho',\n",
       " 'Gemunde',\n",
       " 'Guilhufe',\n",
       " 'Castel?es de Cepeda',\n",
       " 'Milheirós',\n",
       " 'Jovim',\n",
       " 'Travanca',\n",
       " 'Canelas',\n",
       " 'Albergaria-a-Velha',\n",
       " 'Fermel?',\n",
       " 'Frossos',\n",
       " 'S?o Rom?o',\n",
       " 'Santo Tirso',\n",
       " 'Lagoa',\n",
       " 'Ruiv?es']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = []\n",
    "classes = []\n",
    "for i in labels:\n",
    "    if i in classes:\n",
    "        index = classes.index(i)\n",
    "        count[index] += 1\n",
    "    else:\n",
    "        classes.append(i)\n",
    "        count.append(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[736185,\n",
       " 65333,\n",
       " 581761,\n",
       " 28376,\n",
       " 69750,\n",
       " 75217,\n",
       " 49013,\n",
       " 5686,\n",
       " 13842,\n",
       " 20648,\n",
       " 1916,\n",
       " 7691,\n",
       " 5401,\n",
       " 1520,\n",
       " 1697,\n",
       " 804,\n",
       " 76,\n",
       " 588,\n",
       " 7341,\n",
       " 6955,\n",
       " 2224,\n",
       " 792,\n",
       " 59,\n",
       " 5248,\n",
       " 3949,\n",
       " 33,\n",
       " 4107,\n",
       " 8,\n",
       " 20,\n",
       " 463,\n",
       " 741,\n",
       " 1588,\n",
       " 1,\n",
       " 768,\n",
       " 1,\n",
       " 2136,\n",
       " 3,\n",
       " 516,\n",
       " 2,\n",
       " 984,\n",
       " 1,\n",
       " 28,\n",
       " 169,\n",
       " 5,\n",
       " 449,\n",
       " 1,\n",
       " 4,\n",
       " 4,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 4,\n",
       " 1,\n",
       " 259,\n",
       " 77,\n",
       " 6,\n",
       " 61,\n",
       " 34,\n",
       " 1,\n",
       " 1,\n",
       " 38,\n",
       " 5,\n",
       " 1,\n",
       " 1,\n",
       " 6,\n",
       " 80,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 79]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4318385658115557\n",
      "0.038323667312110905\n",
      "0.34125503220670955\n",
      "0.016645070387835536\n",
      "0.04091463418210913\n",
      "0.04412152027635416\n",
      "0.028750522798103438\n",
      "0.0033353492467307886\n",
      "0.008119575144785013\n",
      "0.012111904897379058\n",
      "0.001123905936816073\n",
      "0.004511461670173495\n",
      "0.0031681711715780846\n",
      "0.0008916164008144212\n",
      "0.000995442784330311\n",
      "0.00047161814885183855\n",
      "4.458082004072106e-05\n",
      "0.0003449147655782103\n",
      "0.004306155262091228\n",
      "0.004079731623463355\n",
      "0.0013045755759284689\n",
      "0.00046457907200330367\n",
      "3.4608794505296614e-05\n",
      "0.0030784229417592647\n",
      "0.0023164428729053614\n",
      "1.9357461333470985e-05\n",
      "0.002409124051411071\n",
      "4.6927178990232695e-06\n",
      "1.1731794747558174e-05\n",
      "0.00027159104840597173\n",
      "0.0004346629953970303\n",
      "0.000931504502956119\n",
      "5.865897373779087e-07\n",
      "0.00045050091830623384\n",
      "5.865897373779087e-07\n",
      "0.001252955679039213\n",
      "1.759769212133726e-06\n",
      "0.0003026803044870009\n",
      "1.1731794747558174e-06\n",
      "0.0005772043015798621\n",
      "5.865897373779087e-07\n",
      "1.6424512646581443e-05\n",
      "9.913366561686657e-05\n",
      "2.9329486868895435e-06\n",
      "0.000263378792082681\n",
      "5.865897373779087e-07\n",
      "2.3463589495116347e-06\n",
      "2.3463589495116347e-06\n",
      "1.1731794747558174e-06\n",
      "5.865897373779087e-07\n",
      "5.865897373779087e-07\n",
      "1.1731794747558174e-06\n",
      "2.3463589495116347e-06\n",
      "5.865897373779087e-07\n",
      "0.00015192674198087836\n",
      "4.516740977809897e-05\n",
      "3.519538424267452e-06\n",
      "3.578197398005243e-05\n",
      "1.9944051070848896e-05\n",
      "5.865897373779087e-07\n",
      "5.865897373779087e-07\n",
      "2.229041002036053e-05\n",
      "2.9329486868895435e-06\n",
      "5.865897373779087e-07\n",
      "5.865897373779087e-07\n",
      "3.519538424267452e-06\n",
      "4.6927178990232697e-05\n",
      "1.1731794747558174e-06\n",
      "5.865897373779087e-07\n",
      "1.1731794747558174e-06\n",
      "4.634058925285478e-05\n"
     ]
    }
   ],
   "source": [
    "summ = sum(count)\n",
    "for i in count:\n",
    "    print(float(i/summ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1,\n",
       " 2,\n",
       " 0,\n",
       " 3,\n",
       " 4,\n",
       " 5,\n",
       " 6,\n",
       " 7,\n",
       " 8,\n",
       " 9,\n",
       " 10,\n",
       " 11,\n",
       " 12,\n",
       " 13,\n",
       " 14,\n",
       " 15,\n",
       " 16,\n",
       " 17,\n",
       " 18,\n",
       " 19,\n",
       " 20,\n",
       " 21,\n",
       " 22,\n",
       " 23,\n",
       " 24,\n",
       " 25,\n",
       " 26,\n",
       " 27,\n",
       " 28,\n",
       " 29,\n",
       " 30,\n",
       " 31,\n",
       " 32,\n",
       " 33,\n",
       " 34,\n",
       " 35,\n",
       " 36,\n",
       " 37,\n",
       " 38,\n",
       " 39,\n",
       " 40,\n",
       " 41,\n",
       " 42,\n",
       " 43,\n",
       " 44,\n",
       " 45,\n",
       " 46,\n",
       " 47,\n",
       " 48,\n",
       " 49,\n",
       " 50,\n",
       " 51,\n",
       " 52,\n",
       " 53,\n",
       " 54,\n",
       " 55,\n",
       " 56,\n",
       " 57,\n",
       " 58,\n",
       " 59,\n",
       " 60,\n",
       " 61,\n",
       " 62,\n",
       " 63,\n",
       " 64,\n",
       " 65,\n",
       " 66,\n",
       " 67,\n",
       " 68,\n",
       " 69,\n",
       " 70]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def str2array(string):\n",
    "    \n",
    "    ret = []\n",
    "    \n",
    "    if(len(string) > 2):  \n",
    "        together = ''\n",
    "        for i in string:\n",
    "            if(i != '['):\n",
    "                together += i\n",
    "\n",
    "        first = together.split(\"],\")\n",
    "\n",
    "        for i in range(len(first)):\n",
    "            if(i==len(first)-1):\n",
    "                second = ''\n",
    "                for j in first[i]:\n",
    "                    if(j!=']'):\n",
    "                        second += j\n",
    "                second = second.split(\",\")\n",
    "            else:\n",
    "                second = first[i].split(\",\")\n",
    "            ret.append([float(second[0]), float(second[1])])\n",
    "        return np.array(ret)\n",
    "    \n",
    "    else: return np.array(ret)\n",
    "\n",
    "def tran_label(string):\n",
    "    \n",
    "    point = str2array(string)\n",
    "    \n",
    "    if(len(point) == 0):\n",
    "        return 999999\n",
    "    else:\n",
    "        for i in range(len(area) - 1):\n",
    "            if((point[-1][0]<area[i][0]) & (point[-1][1]<area[i][1]) & (point[-1][0]>=(area[i][0]-0.15)) \n",
    "               & (point[-1][1]>=(area[i][1]-0.15))):\n",
    "                find = True \n",
    "                return i   \n",
    "\n",
    "def pick_data(data, labels, data_length):\n",
    "    ret_train = []\n",
    "    ret_label = []\n",
    "    n = 0\n",
    "    for i in range(len(data)):\n",
    "        if(len(data[i]) > data_length & labels[i] != 0):\n",
    "            split = len(data[i])//data_length\n",
    "            ret_train.append([])\n",
    "            for j in range(data_length):\n",
    "                ret_train[n].append(data[i][split*j][0])\n",
    "                ret_train[n].append(data[i][split*j][1])\n",
    "            ret_label.append(labels[i])\n",
    "            n += 1\n",
    "    return ret_train, ret_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "track_data = pd.read_csv(\"../train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "array = track_data[\"POLYLINE\"].apply(str2array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "track_data = []\n",
    "for i in range(len(array)):\n",
    "    if(len(array[i])>0):\n",
    "        track_data.append(array[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1704769\n"
     ]
    }
   ],
   "source": [
    "print(len(track_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pick the usefull data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_length = 10\n",
    "\n",
    "train_data, train_label = pick_data(track_data, labels, data_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dict = {'train_data10': train_data, 'train_label10': train_label}\n",
    "with open('./train_data10.pickle','wb') as file:\n",
    "    pickle.dump(data_dict, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(train_data, train_label, test_size = 0.2, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.placeholder(tf.float32,(None, 20))\n",
    "\n",
    "# Arguments used for tf.truncated_normal, randomly defines variables for the weights and biases for each layer\n",
    "mu = 0\n",
    "sigma = 0.1\n",
    "\n",
    "# Layer 1: Input = 20. Output = 40.\n",
    "fc1_W = tf.Variable(tf.truncated_normal(shape=(20, 40), mean = mu, stddev = sigma))\n",
    "fc1_b = tf.Variable(tf.zeros(40))\n",
    "fc1_lin   = tf.matmul(x, fc1_W) + fc1_b\n",
    "\n",
    "# Activation.\n",
    "fc1 = tf.nn.relu(fc1_lin)\n",
    "\n",
    "# Layer 2: Input = 40. Output = 70.\n",
    "fc2_W = tf.Variable(tf.truncated_normal(shape=(40, 70), mean = mu, stddev = sigma))\n",
    "fc2_b = tf.Variable(tf.zeros(70))\n",
    "logits   = tf.matmul(fc1, fc2_W) + fc2_b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = tf.placeholder(tf.int32,(None))\n",
    "one_hot_y = tf.one_hot(y,70)\n",
    "\n",
    "learning_rate = 0.001\n",
    "\n",
    "cross_entropy = tf.nn.softmax_cross_entropy_with_logits(labels = one_hot_y, logits = logits)\n",
    "loss_operation = tf.reduce_mean(cross_entropy)\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate = learning_rate)\n",
    "training_operation = optimizer.minimize(loss_operation)\n",
    "\n",
    "saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tensorflow parameters\n",
    "epoches = 50\n",
    "batch_size = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Evaluation accuracy\n",
    "\n",
    "correct_prediction = tf.equal(tf.argmax(logits, 1), tf.argmax(one_hot_y, 1))\n",
    "accuracy_operation = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "\n",
    "def evaluate(X_data, y_data):\n",
    "    num_examples = len(X_data)\n",
    "    total_accuracy = 0\n",
    "    sess = tf.get_default_session()\n",
    "    for offset in range(0, num_examples, batch_size):\n",
    "        batch_x, batch_y = X_data[offset:offset+batch_size], y_data[offset:offset+batch_size]\n",
    "        accuracy = sess.run(accuracy_operation, feed_dict={x: batch_x, y: batch_y})\n",
    "        total_accuracy += (accuracy * len(batch_x))\n",
    "    return total_accuracy / num_examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ......\n",
      "\n",
      "Model saved with accuracy: 0.2759144357202544\n",
      "EPOCH 1 ...\n",
      "Validation Accuracy = 0.276\n",
      "\n",
      "Model saved with accuracy: 0.2759144357202544\n",
      "Model saved with accuracy: 0.2759144357202544\n",
      "Model saved with accuracy: 0.2759144357202544\n",
      "Model saved with accuracy: 0.2759144357202544\n",
      "Model saved with accuracy: 0.2759144357202544\n",
      "EPOCH 6 ...\n",
      "Validation Accuracy = 0.276\n",
      "\n",
      "Model saved with accuracy: 0.2759144357202544\n",
      "Model saved with accuracy: 0.2759144357202544\n",
      "Model saved with accuracy: 0.2759144357202544\n",
      "Model saved with accuracy: 0.2759144357202544\n",
      "Model saved with accuracy: 0.2759144357202544\n",
      "EPOCH 11 ...\n",
      "Validation Accuracy = 0.276\n",
      "\n",
      "Model saved with accuracy: 0.2759144357202544\n",
      "Model saved with accuracy: 0.2759144357202544\n",
      "Model saved with accuracy: 0.2759144357202544\n",
      "Model saved with accuracy: 0.2759144357202544\n",
      "Model saved with accuracy: 0.2759144357202544\n",
      "EPOCH 16 ...\n",
      "Validation Accuracy = 0.276\n",
      "\n",
      "Model saved with accuracy: 0.2759144357202544\n",
      "Model saved with accuracy: 0.2759144357202544\n",
      "Model saved with accuracy: 0.2759144357202544\n",
      "Model saved with accuracy: 0.2759144357202544\n",
      "Model saved with accuracy: 0.2759144357202544\n",
      "EPOCH 21 ...\n",
      "Validation Accuracy = 0.276\n",
      "\n",
      "Model saved with accuracy: 0.2759144357202544\n",
      "Model saved with accuracy: 0.2759144357202544\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-45-870be41b970b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     12\u001b[0m             \u001b[0mend\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0moffset\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m             \u001b[0mbatch_x\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_y\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX_train\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0moffset\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mend\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0moffset\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mend\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m             \u001b[0msess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtraining_operation\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mfeed_dict\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mbatch_x\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mbatch_y\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m         \u001b[0mvalidation_accuracy\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    875\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    876\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 877\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    878\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    879\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1098\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1099\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m-> 1100\u001b[1;33m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[0;32m   1101\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1102\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1270\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1271\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[1;32m-> 1272\u001b[1;33m                            run_metadata)\n\u001b[0m\u001b[0;32m   1273\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1274\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1276\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1277\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1278\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1279\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1280\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1261\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1262\u001b[0m       return self._call_tf_sessionrun(\n\u001b[1;32m-> 1263\u001b[1;33m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[0;32m   1264\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1265\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[1;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[0;32m   1348\u001b[0m     return tf_session.TF_SessionRun_wrapper(\n\u001b[0;32m   1349\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1350\u001b[1;33m         run_metadata)\n\u001b[0m\u001b[0;32m   1351\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1352\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_call_tf_sessionprun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "n_train = len(x_train)\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    print('Training ......')\n",
    "    print()\n",
    "    max_acc = 0\n",
    "\n",
    "    for i in range(epoches):\n",
    "        X_train,y_train = shuffle(x_train,y_train) # shuffle the data\n",
    "        for offset in range(0,n_train,batch_size):\n",
    "            end = offset + batch_size\n",
    "            batch_x, batch_y = X_train[offset:end],y_train[offset:end]\n",
    "            sess.run(training_operation,feed_dict = {x:batch_x, y:batch_y})\n",
    "\n",
    "        validation_accuracy = evaluate(x_test, y_test)\n",
    "        if(max_acc <= validation_accuracy):\n",
    "            max_acc = validation_accuracy\n",
    "            saver.save(sess, './result')\n",
    "            print(\"Model saved with accuracy:\", max_acc)\n",
    "        if i%5 == 0:\n",
    "            print(\"EPOCH {} ...\".format(i+1))\n",
    "            print(\"Validation Accuracy = {:.3f}\".format(validation_accuracy))\n",
    "#             print('Can be better, continue training...')\n",
    "            print()\n",
    "\n",
    "    print(\"maximal accuracy is:\", max_acc)\n",
    "    print(\"End training\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
